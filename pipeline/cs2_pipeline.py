from scrapers.results_scraper import ResultsScraper
from scrapers.match_scraper import MatchScraper
from storage.database import Database
from utils.log_manager import get_logger

class CS2AnalyticsPipeline:
    def __init__(self):
        """Initialize pipeline components."""
        self.logger = get_logger(self.__class__.__name__)
        self.results_scraper = ResultsScraper()
        self.match_scraper = MatchScraper()
        self.db = Database()

    def run(self):
        """Execute the full CS2 analytics pipeline."""
        self.logger.info("âœ… Starting full CS2 pipeline.")

        # âœ… Step 1: Scrape Match Results
        self.logger.info("ğŸ”„ Scraping match results...")
        results = self.results_scraper.fetch_results()
        if not results:
            self.logger.warning("âš ï¸ No new matches found.")
            return

        # âœ… Step 2: Scrape Match Details (Includes Demo Links)
        self.logger.info("ğŸ”„ Scraping match details & demo links...")
        match_details = [self.match_scraper.fetch_match_data(url) for url in results]
        if not match_details:
            self.logger.warning("âš ï¸ No match details scraped.")
            return

        # âœ… Step 3: Store Data in the Database
        self.logger.info("ğŸ’¾ Storing match data in the database...")
        self.db.store_matches(match_details)
        self.logger.info("âœ… Match data successfully stored.")

        self.logger.info("ğŸš€ CS2 pipeline completed.")
